{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60092b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import csv\n",
    "\n",
    "# --- ViT Model (No changes needed in ViT class itself, only in num_classes when instantiating) ---\n",
    "from einops import rearrange, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "# helpers\n",
    "def pair(t):\n",
    "    return t if isinstance(t, tuple) else (t, t)\n",
    "\n",
    "# classes\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, hidden_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(dim, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        project_out = not (heads == 1 and dim_head == dim)\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attend = nn.Softmax(dim = -1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n",
    "\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.norm(x)\n",
    "\n",
    "        qkv = self.to_qkv(x).chunk(3, dim = -1)\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n",
    "\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale\n",
    "\n",
    "        attn = self.attend(dots)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        out = torch.matmul(attn, v)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        return self.to_out(out)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.layers = nn.ModuleList([])\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.ModuleList([\n",
    "                Attention(dim, heads = heads, dim_head = dim_head, dropout = dropout),\n",
    "                FeedForward(dim, mlp_dim, dropout = dropout)\n",
    "            ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for attn, ff in self.layers:\n",
    "            x = attn(x) + x\n",
    "            x = ff(x) + x\n",
    "\n",
    "        return self.norm(x)\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n",
    "        super().__init__()\n",
    "        image_height, image_width = pair(image_size)\n",
    "        patch_height, patch_width = pair(patch_size)\n",
    "\n",
    "        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n",
    "\n",
    "        num_patches = (image_height // patch_height) * (image_width // patch_width)\n",
    "        patch_dim = channels * patch_height * patch_width\n",
    "        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n",
    "\n",
    "        self.to_patch_embedding = nn.Sequential(\n",
    "            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_height, p2 = patch_width),\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim),\n",
    "        )\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.to_latent = nn.Identity()\n",
    "\n",
    "        # The final MLP head will output 1 logit for binary classification\n",
    "        self.mlp_head = nn.Linear(dim, num_classes)\n",
    "\n",
    "    def forward(self, img):\n",
    "        x = self.to_patch_embedding(img)\n",
    "        b, n, _ = x.shape\n",
    "\n",
    "        cls_tokens = repeat(self.cls_token, '1 1 d -> b 1 d', b = b)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        x += self.pos_embedding[:, :(n + 1)]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.transformer(x)\n",
    "\n",
    "        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n",
    "\n",
    "        x = self.to_latent(x)\n",
    "        return self.mlp_head(x)\n",
    "\n",
    "\n",
    "\n",
    "# --- Custom Dataset (No changes needed here for binary classification specifically) ---\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Ensure there are exactly two classes for binary classification\n",
    "        if len(self.classes) != 2:\n",
    "            raise ValueError(f\"Expected 2 classes for binary classification, but found {len(self.classes)}: {self.classes}\")\n",
    "        \n",
    "        for cls in self.classes:\n",
    "            cls_path = os.path.join(root_dir, cls)\n",
    "            for img_name in os.listdir(cls_path):\n",
    "                self.image_paths.append(os.path.join(cls_path, img_name))\n",
    "                self.labels.append(self.class_to_idx[cls])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        # Labels for BCEWithLogitsLoss need to be float and shaped [batch_size, 1]\n",
    "        label = torch.tensor(self.labels[idx]).float().unsqueeze(0) \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    losses, preds, targets = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # For BCEWithLogitsLoss, labels need to be float and shape (batch_size, 1)\n",
    "            # Loss calculation remains the same\n",
    "            loss = criterion(outputs, labels) \n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            # Apply sigmoid and threshold for binary predictions\n",
    "            # outputs is (batch_size, 1)\n",
    "            binary_preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            \n",
    "            preds.extend(binary_preds.flatten()) # Flatten to 1D array\n",
    "            targets.extend(labels.cpu().numpy().flatten()) # Flatten to 1D array\n",
    "\n",
    "    acc = accuracy_score(targets, preds)\n",
    "    # For binary classification, 'binary' average is often suitable for precision/recall/f1.\n",
    "    # 'macro' also works if you want to treat each class equally.\n",
    "    prec, recall, f1, _ = precision_recall_fscore_support(targets, preds, average='binary', zero_division=0)\n",
    "    \n",
    "    return np.mean(losses), acc, prec, recall, f1, preds, targets\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, train_loader, val_loader, test_loader, device,\n",
    "                num_epochs, save_policy='min', base_output_dir='logs', class_names=None):\n",
    "\n",
    "    # Create timestamped main directory\n",
    "    now = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "   # run_dir = os.path.join(base_output_dir, f'run_{now}')\n",
    "    run_dir=base_output_dir\n",
    "    model_dir = os.path.join(run_dir, 'models')\n",
    "    metric_dir = os.path.join(run_dir, 'metrics')\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    os.makedirs(metric_dir, exist_ok=True)\n",
    "\n",
    "    best_val_score = float('-inf')\n",
    "    worst_val_score = float('inf') # For 'min' save policy with loss\n",
    "    start_training_time = time.time()\n",
    " \n",
    "    # Prepare header\n",
    "    train_log_path = os.path.join(metric_dir, 'train_log.txt')\n",
    "    val_log_path = os.path.join(metric_dir, 'val_log.txt')\n",
    "\n",
    "    with open(train_log_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Time'])\n",
    "\n",
    "    with open(val_log_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Epoch', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1', 'Time'])\n",
    "\n",
    "    print(\"Starting time:\", now.replace(\"_\", \" \"))\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        model.train()\n",
    "        train_losses, train_preds, train_targets = [], [], []\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Labels already formatted as float().unsqueeze(0) in CustomDataset __getitem__\n",
    "            loss = criterion(outputs, labels) \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_losses.append(loss.item())\n",
    "            # Apply sigmoid and threshold for binary predictions\n",
    "            binary_preds = (torch.sigmoid(outputs) > 0.5).int().cpu().numpy()\n",
    "            train_preds.extend(binary_preds.flatten())\n",
    "            train_targets.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "        # Train metrics\n",
    "        train_loss = np.mean(train_losses)\n",
    "        train_acc = accuracy_score(train_targets, train_preds)\n",
    "        train_prec, train_rec, train_f1, _ = precision_recall_fscore_support(train_targets, train_preds, average='binary', zero_division=0)\n",
    "\n",
    "        # Validation metrics\n",
    "        val_loss, val_acc, val_prec, val_rec, val_f1, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
    "\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "\n",
    "        print(f\"Epoch [{epoch}/{num_epochs}]\")\n",
    "        print(f\"Train | Loss: {train_loss:.4f} | Acc: {train_acc:.4f} | Prec: {train_prec:.4f} | Rec: {train_rec:.4f} | F1: {train_f1:.4f}\")\n",
    "        print(f\"Val   | Loss: {val_loss:.4f} | Acc: {val_acc:.4f} | Prec: {val_prec:.4f} | Rec: {val_rec:.4f} | F1: {val_f1:.4f}\")\n",
    "        print(f\"Epoch Time: {str(timedelta(seconds=epoch_time))} sec\\n\")\n",
    "\n",
    "        # Append metrics in CSV-like format to .txt files (rounded to 4 decimal places)\n",
    "        with open(train_log_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                round(train_loss, 4),\n",
    "                round(train_acc, 4),\n",
    "                round(train_prec, 4),\n",
    "                round(train_rec, 4),\n",
    "                round(train_f1, 4),\n",
    "                round(epoch_time, 4)\n",
    "            ])\n",
    "\n",
    "        with open(val_log_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\n",
    "                epoch,\n",
    "                round(val_loss, 4),\n",
    "                round(val_acc, 4),\n",
    "                round(val_prec, 4),\n",
    "                round(val_rec, 4),\n",
    "                round(val_f1, 4),\n",
    "                round(epoch_time, 4)\n",
    "            ])\n",
    "\n",
    "        # Save model based on policy\n",
    "        epoch_model_path = os.path.join(model_dir, f'epoch_{epoch:04d}.pt')\n",
    "\n",
    "        if save_policy == 'max':\n",
    "            if val_acc > best_val_score:\n",
    "                best_val_score = val_acc\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pt'))\n",
    "                print(f\"Validation accuracy improved to {val_acc:.4f}. Saving best model.\")\n",
    "            torch.save(model.state_dict(), epoch_model_path) # Always save current epoch model if max\n",
    "\n",
    "        elif save_policy == 'min':\n",
    "            if val_loss < worst_val_score:\n",
    "                worst_val_score = val_loss\n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pt'))\n",
    "                print(f\"Validation loss improved to {val_loss:.4f}. Saving best model.\")\n",
    "            torch.save(model.state_dict(), epoch_model_path) # Always save current epoch model if min\n",
    "\n",
    "        elif save_policy == 'all':\n",
    "            torch.save(model.state_dict(), epoch_model_path)\n",
    "\n",
    "        elif save_policy == 'last':\n",
    "            torch.save(model.state_dict(), epoch_model_path)\n",
    "            # For 'last', the 'best_model.pt' will simply be the last epoch's model\n",
    "            if epoch == num_epochs: \n",
    "                torch.save(model.state_dict(), os.path.join(model_dir, 'best_model.pt'))\n",
    "\n",
    "    total_time = time.time() - start_training_time\n",
    "    print(\"Finish time:\", datetime.now().strftime(\"%d-%m-%Y %H:%M:%S\"))\n",
    "    print(f\"Total training time: {str(timedelta(seconds=total_time))} seconds\")\n",
    "\n",
    "    print(\"\\nðŸŽ¯ Final Evaluation on Test Set (using last epoch's model):\")\n",
    "    test_loss, test_acc, test_prec, test_rec, test_f1, test_preds, test_targets = evaluate_model(model, test_loader, criterion, device)\n",
    "    print(f\"Test | Loss: {test_loss:.4f} | Acc: {test_acc:.4f} | Prec: {test_prec:.4f} | Rec: {test_rec:.4f} | F1: {test_f1:.4f}\")\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(test_targets, test_preds)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # Ensure class_names are correct for binary (e.g., ['Class 0', 'Class 1'])\n",
    "    xticks = yticks = class_names if class_names and len(class_names) == 2 else ['Class 0', 'Class 1']\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=xticks, yticklabels=yticks)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(metric_dir, \"confusion_matrix.png\"))\n",
    "    plt.close()\n",
    "\n",
    "   \n",
    "\n",
    "    # Save final test metrics to a structured .txt file\n",
    "    test_log_path = os.path.join(metric_dir, 'test_metrics.txt')\n",
    "    with open(test_log_path, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['Loss', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "        writer.writerow([\n",
    "            round(test_loss, 4),\n",
    "            round(test_acc, 4),\n",
    "            round(test_prec, 4),\n",
    "            round(test_rec, 4),\n",
    "            round(test_f1, 4)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706d16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc606a",
   "metadata": {},
   "source": [
    "# normal train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5cec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Settings ---\n",
    "image_dir = 'DataSet/top-agriculture-crop-disease'    # Folder where images are stored\n",
    "image_size = 32 # Make sure this matches the image_size of your ViT model\n",
    "batch_size = 32\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "num_workers = 4 # Adjust based on your system's capabilities\n",
    "save_dir='logs'\n",
    "\n",
    "# --- Transforms ---\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# --- Load full dataset ---\n",
    "# The CustomDataset now expects exactly 2 classes in the root_dir\n",
    "full_dataset = CustomDataset(image_dir) \n",
    "num_samples = len(full_dataset)\n",
    "num_val = int(num_samples * val_ratio)\n",
    "num_test = int(num_samples * test_ratio)\n",
    "num_train = num_samples - num_val - num_test\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 42  # You can change this to any integer\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "# --- Split dataset ---\n",
    "train_dataset, val_dataset, test_dataset = random_split(full_dataset, [num_train, num_val, num_test], generator=generator)\n",
    "\n",
    "# Assign transforms after split\n",
    "# Note: For random_split, you access the original dataset's transform via .dataset\n",
    "# This approach works if the transform is applied to the underlying full dataset.\n",
    "# A more robust way for random_split when transforms differ is to pass the transform\n",
    "# directly during the __getitem__ of the dataset wrapper, but for simplicity, this often works.\n",
    "# For binary classification, make sure your data folder 'top-agriculture-crop-disease'\n",
    "# contains exactly two subfolders (e.g., 'healthy' and 'diseased').\n",
    "train_dataset.dataset.transform = train_transform\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "test_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# --- DataLoaders ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# --- Class Info ---\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names) # This should now be 2\n",
    "print(f\"Loaded dataset with {num_classes} classes: {class_names}\")\n",
    "\n",
    "\n",
    "# Instantiate the ViT model for binary classification\n",
    "model = ViT(\n",
    "    image_size = image_size,  # Use the image_size from settings\n",
    "    patch_size = 16,\n",
    "    num_classes = 1,  # Set to 1 for binary classification with BCEWithLogitsLoss\n",
    "    dim = 192,\n",
    "    depth = 9,\n",
    "    heads = 12,\n",
    "    mlp_dim = 384,\n",
    "    dropout = 0,\n",
    "    emb_dropout = 0\n",
    ")\n",
    "\n",
    "# Use BCEWithLogitsLoss for binary classification\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === Tarihli ana klasÃ¶r oluÅŸtur ===\n",
    "run_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "run_dir = os.path.join(save_dir, f'run_{run_time}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "print(f\"ðŸ“ Saving all folds under: {run_dir}\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "train_model(model, criterion, optimizer, train_loader, val_loader, test_loader, device,\n",
    "            num_epochs=2, save_policy='last', base_output_dir=run_dir, class_names=class_names) # Pass class_names for confusion matrix\n",
    "\n",
    "# You can also load and evaluate a specific saved model after training if needed\n",
    "# save_dir should point to the correct run directory, e.g., 'logs/run_2025-07-15_22-17-57/models'\n",
    "# Replace this with the actual path of your saved model from the 'train_model' output\n",
    "# save_dir_for_inference = \"./logs/run_YYYY-MM-DD_HH-MM-SS/models\" \n",
    "# model.load_state_dict(torch.load(os.path.join(save_dir_for_inference, 'best_model.pt')))\n",
    "# _, acc, prec, rec, f1, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "# print(f\"Best Model (Loaded for Inference) | Acc: {acc:.4f} | Prec: {prec:.4f} | Rec: {rec:.4f} | F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a133f2",
   "metadata": {},
   "source": [
    "# Kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dbf8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# === Tarihli ana klasÃ¶r oluÅŸtur ===\n",
    "run_time = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "run_dir = os.path.join(save_dir, f'run_{run_time}')\n",
    "os.makedirs(run_dir, exist_ok=True)\n",
    "print(f\"ðŸ“ Saving all folds under: {run_dir}\")\n",
    "\n",
    "# === Parameters ===\n",
    "k_folds = 5\n",
    "image_dir = 'DataSet/top-agriculture-crop-disease'\n",
    "image_size = 256\n",
    "batch_size = 32\n",
    "num_epochs = 2\n",
    "save_policy = 'last'\n",
    "save_dir = 'logs'\n",
    "test_ratio = 0.1\n",
    "num_workers = 4\n",
    "seed = 42\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# === Transforms ===\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n",
    "\n",
    "# === Load full dataset ===\n",
    "full_dataset = CustomDataset(image_dir)\n",
    "class_names = full_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# === Step 1: Split off test set ===\n",
    "total_size = len(full_dataset)\n",
    "test_size = int(total_size * test_ratio)\n",
    "trainval_size = total_size - test_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(seed)\n",
    "trainval_dataset, test_dataset = random_split(full_dataset, [trainval_size, test_size], generator=generator)\n",
    "\n",
    "# Fix transforms\n",
    "trainval_dataset.dataset.transform = None  # Will apply inside each fold\n",
    "test_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# StratifiedKFold iÃ§in: trainval_dataset iÃ§indeki sÄ±ralamaya gÃ¶re alÄ±nÄ±r\n",
    "X = list(range(len(trainval_dataset)))\n",
    "y = [int(label.item()) for _, label in trainval_dataset]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=k_folds, shuffle=True, random_state=seed)\n",
    "\n",
    "all_fold_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"\\nðŸŒ€ Fold {fold+1}/{k_folds}\")\n",
    "\n",
    "    train_subset = Subset(trainval_dataset, train_idx)\n",
    "    val_subset = Subset(trainval_dataset, val_idx)\n",
    "\n",
    "    # Transforms uygulanÄ±r\n",
    "    train_subset.dataset.transform = train_transform\n",
    "    val_subset.dataset.transform = val_test_transform\n",
    "\n",
    "    # DataLoader'lar\n",
    "    train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    # Model, optimizer, criterion yeniden tanÄ±mlanÄ±r\n",
    "    model = ViT(\n",
    "        image_size=image_size,\n",
    "        patch_size=16,\n",
    "        num_classes=1,\n",
    "        dim=192,\n",
    "        depth=9,\n",
    "        heads=12,\n",
    "        mlp_dim=384,\n",
    "        dropout=0,\n",
    "        emb_dropout=0\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    \n",
    "     # Fold iÃ§in klasÃ¶r oluÅŸtur\n",
    "    fold_save_dir = os.path.join(run_dir, f'fold_{fold+1}')\n",
    "    os.makedirs(fold_save_dir, exist_ok=True)\n",
    "\n",
    "    train_model(model, criterion, optimizer, train_loader, val_loader, test_loader, device,\n",
    "                num_epochs=num_epochs, save_policy=save_policy,\n",
    "                base_output_dir=fold_save_dir, class_names=class_names)\n",
    "\n",
    "     # Final test evaluation\n",
    "    test_loss, test_acc, test_prec, test_rec, test_f1, _, _ = evaluate_model(model, test_loader, criterion, device)\n",
    "\n",
    "    with open(os.path.join(fold_save_dir, 'test_metrics.txt'), 'w', newline='') as f:\n",
    "        writer = csv.writer(f, delimiter='\\t')\n",
    "        writer.writerow(['Loss', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "        writer.writerow([\n",
    "            round(test_loss, 4),\n",
    "            round(test_acc, 4),\n",
    "            round(test_prec, 4),\n",
    "            round(test_rec, 4),\n",
    "            round(test_f1, 4)\n",
    "        ])\n",
    "\n",
    "    all_fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'loss': test_loss,\n",
    "        'acc': test_acc,\n",
    "        'prec': test_prec,\n",
    "        'rec': test_rec,\n",
    "        'f1': test_f1\n",
    "    })\n",
    "\n",
    "# ==== Save average results as CSV-formatted text ====\n",
    "avg_metrics = {\n",
    "    'loss': np.mean([r['loss'] for r in all_fold_results]),\n",
    "    'acc': np.mean([r['acc'] for r in all_fold_results]),\n",
    "    'prec': np.mean([r['prec'] for r in all_fold_results]),\n",
    "    'rec': np.mean([r['rec'] for r in all_fold_results]),\n",
    "    'f1': np.mean([r['f1'] for r in all_fold_results])\n",
    "}\n",
    "\n",
    "with open(os.path.join(run_dir, 'kfold_results.txt'), 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter='\\t')\n",
    "    writer.writerow(['Fold', 'Loss', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "    for r in all_fold_results:\n",
    "        writer.writerow([\n",
    "            r['fold'],\n",
    "            round(r['loss'], 4),\n",
    "            round(r['acc'], 4),\n",
    "            round(r['prec'], 4),\n",
    "            round(r['rec'], 4),\n",
    "            round(r['f1'], 4)\n",
    "        ])\n",
    "    writer.writerow([])\n",
    "    writer.writerow(['Average', \n",
    "                     round(avg_metrics['loss'], 4),\n",
    "                     round(avg_metrics['acc'], 4),\n",
    "                     round(avg_metrics['prec'], 4),\n",
    "                     round(avg_metrics['rec'], 4),\n",
    "                     round(avg_metrics['f1'], 4)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a8874c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8192c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
